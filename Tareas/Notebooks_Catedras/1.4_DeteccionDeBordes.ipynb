{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CC5213 - Recuperaci칩n de Informaci칩n Multimedia\n",
    "=="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slides 1.4 - Detecci칩n de Bordes\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando OpenCV 4.4.0 con Python 3.7.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy\n",
    "import cv2\n",
    "from PyQt5.QtWidgets import QApplication, QFileDialog\n",
    "\n",
    "def mostrar_imagen(window_name, imagen):\n",
    "    MAX_WIDTH = 700\n",
    "    MAX_HEIGHT = 500\n",
    "    if imagen.shape[0] > MAX_HEIGHT or imagen.shape[1] > MAX_WIDTH:\n",
    "        #reducir tama침o\n",
    "        fh = MAX_HEIGHT / imagen.shape[0]\n",
    "        fw = MAX_WIDTH / imagen.shape[1]\n",
    "        escala = min(fh, fw)\n",
    "        imagen = cv2.resize(imagen, (0,0), fx=escala, fy=escala)\n",
    "    #mostrar en pantalla\n",
    "    cv2.imshow(window_name, imagen)\n",
    "\n",
    "def ui_select_video():\n",
    "    app = QApplication(list());\n",
    "    options = QFileDialog.Options()\n",
    "    filename, _ = QFileDialog.getOpenFileName(None, \"Videos\", \".\", \"Videos (*.mp4 *.mpg *.avi)\", options=options)\n",
    "    if not filename:\n",
    "        filename = \"0\" # id de la webcam: 0=primera webcam, 1=segunda webcam\n",
    "    return filename\n",
    "\n",
    "def abrir_imagen(filename):\n",
    "    imagen_color = cv2.imread(filename, cv2.IMREAD_COLOR)\n",
    "    if imagen_color is None:\n",
    "        raise Exception(\"error abriendo {}\".format(filename))\n",
    "    return imagen_color\n",
    "\n",
    "def agregar_texto(imagen, texto):\n",
    "    fontFace = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    fontScale = 0.7\n",
    "    thickness = 2\n",
    "    textSize = cv2.getTextSize(texto, fontFace, fontScale, thickness)\n",
    "    position1 = (10,30)\n",
    "    position2 = (20,40)\n",
    "    cv2.rectangle(imagen, position1, position2, (0,255,0), -1)\n",
    "    position3 = (10,30)\n",
    "    cv2.putText(imagen, texto, position3, fontFace, fontScale, (200,0,0), thickness, cv2.LINE_AA)\n",
    "\n",
    "def normalizar(imagen, valorAbsoluto = False, min0Max255 = False):\n",
    "    img = imagen\n",
    "    if valorAbsoluto:\n",
    "        img = numpy.abs(imagen)\n",
    "    if min0Max255:\n",
    "        img2 = cv2.normalize(img, dst=None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "        img = img2\n",
    "    return img\n",
    "\n",
    "print(\"Usando OpenCV {} con Python {}.{}.{}\".format(cv2.__version__, sys.version_info.major, sys.version_info.minor, sys.version_info.micro))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 1 - Sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abriendo webcam 0...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b098191b52ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mui_select_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mrun_ejemplo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FIN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-b098191b52ff>\u001b[0m in \u001b[0;36mrun_ejemplo\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0msobel_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcapture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabrir_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "def run_ejemplo(filename):\n",
    "    global sobel_threshold, delta\n",
    "    imagen_color = abrir_imagen(filename)\n",
    "    imagen_gris = cv2.cvtColor(imagen_color, cv2.COLOR_BGR2GRAY)\n",
    "    mostrar_imagen(\"IMAGEN\", frame_gris)\n",
    "    #calcular filtro de sobel\n",
    "    sobelX = cv2.Sobel(imagen_gris, ddepth=cv2.CV_32F, dx=1, dy=0, ksize=3)\n",
    "    sobelY = cv2.Sobel(imagen_gris, ddepth=cv2.CV_32F, dx=0, dy=1, ksize=3)\n",
    "    mostrar_imagen(\"X\", normalizar(sobelX, valorAbsoluto=True, min0Max255=True))\n",
    "    mostrar_imagen(\"Y\", normalizar(sobelY, valorAbsoluto=True, min0Max255=True))\n",
    "    #magnitud del gradiente\n",
    "    magnitud = numpy.sqrt(numpy.square(sobelX) + numpy.square(sobelY) )\n",
    "    mostrar_imagen(\"MAGNITUD GRADIENTE\", normalizar(magnitud, min0Max255=True))\n",
    "    #aproximacion de la magnitud del gradiente\n",
    "    #aprox = numpy.abs(sobelX) + numpy.abs(sobelY)\n",
    "    #mostrar_imagen(\"APROX GRADIENTE\", normalizar(aprox, min0Max255=True))\n",
    "    #umbral sobre la magnitud del gradiente\n",
    "    retval, bordes = cv2.threshold(magnitud, thresh=sobel_threshold, maxval=255, type=cv2.THRESH_BINARY)\n",
    "    agregar_texto(bordes, \"th={}\".format(sobel_threshold))\n",
    "    mostrar_imagen(\"BORDES\", bordes)\n",
    "    #esperar por una tecla\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == ord(' '):\n",
    "        key = cv2.waitKey(0)\n",
    "    if key == ord('q') or key == 27:\n",
    "        break\n",
    "    elif key == ord('a'):\n",
    "        sobel_threshold += delta\n",
    "    elif key == ord('z'):\n",
    "        if sobel_threshold - delta > 0:\n",
    "            sobel_threshold -= delta\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "sobel_threshold = 51\n",
    "delta = 5\n",
    "\n",
    "filename = ui_select_video()\n",
    "run_ejemplo(filename)\n",
    "\n",
    "print(\"FIN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 2 - Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ejemplo(filename):\n",
    "    global canny_threshold_1, canny_threshold_2, delta\n",
    "    capture = abrir_video(filename)\n",
    "    while capture.grab():\n",
    "        retval, frame = capture.retrieve()\n",
    "        if not retval:\n",
    "            continue\n",
    "        #convertir a gris\n",
    "        frame_gris = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        mostrar_imagen(\"VIDEO\", frame_gris)\n",
    "        #calcular canny\n",
    "        frame_canny = cv2.Canny(frame_gris, threshold1=canny_threshold_1, threshold2=canny_threshold_2)\n",
    "        agregar_texto(frame_canny, \"th={}-{}\".format(canny_threshold_1, canny_threshold_2))\n",
    "        mostrar_imagen(\"CANNY\", frame_canny)\n",
    "        #esperar por una tecla\n",
    "        key = cv2.waitKey(10)\n",
    "        if key == ord(' '):\n",
    "            key = cv2.waitKey(0)\n",
    "        if key == -1:\n",
    "            continue\n",
    "        elif key == ord('q') or key == 27:\n",
    "            break\n",
    "        elif key == ord('a'):\n",
    "            canny_threshold_1 += delta\n",
    "        elif key == ord('z'):\n",
    "            if canny_threshold_1 - delta > 0:\n",
    "                canny_threshold_1 -= delta\n",
    "        elif key == ord('s'):\n",
    "            canny_threshold_2 += delta\n",
    "        elif key == ord('x'):\n",
    "            if canny_threshold_2 - delta > 0:\n",
    "                canny_threshold_2 -= delta\n",
    "        else:\n",
    "            print(\"unknown key '{}' ({})\".format(chr(key), key))\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "canny_threshold_1 = 51\n",
    "canny_threshold_2 = 301\n",
    "delta = 10\n",
    "\n",
    "filename = ui_select_video()\n",
    "ejemplo(filename)\n",
    "\n",
    "print(\"FIN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 3 - Difference of Gaussians (DoG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ejemplo(filename):\n",
    "    global sigma1, sigma2, threshold\n",
    "    capture = abrir_video(filename)\n",
    "    while capture.grab():\n",
    "        retval, frame = capture.retrieve()\n",
    "        if not retval:\n",
    "            continue\n",
    "        #convertir a gris\n",
    "        frame_gris = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        mostrar_imagen(\"VIDEO\", frame_gris)\n",
    "        #calcular DoG\n",
    "        blur1 = cv2.GaussianBlur(frame_gris, (sigma1, sigma1), 0)\n",
    "        blur2 = cv2.GaussianBlur(frame_gris, (sigma2, sigma2), 0)\n",
    "        frame_diff = cv2.subtract(blur1, blur2)\n",
    "        mostrar_imagen(\"Diff\", normalizar(frame_diff, min0Max255=True))\n",
    "        threshold = round(threshold, 2)\n",
    "        th, frame_bin = cv2.threshold(frame_diff, threshold, 255, cv2.THRESH_BINARY)\n",
    "        agregar_texto(frame_bin, \"th={}\".format(threshold))\n",
    "        mostrar_imagen(\"BIN\", normalizar(frame_bin, min0Max255=True))\n",
    "        #esperar por una tecla\n",
    "        key = cv2.waitKey(10)\n",
    "        if key == ord(' '):\n",
    "            key = cv2.waitKey(0)\n",
    "        if key == -1:\n",
    "            continue\n",
    "        elif key == ord('q') or key == 27:\n",
    "            break\n",
    "        elif key == ord('a'):\n",
    "            threshold += delta\n",
    "        elif key == ord('z'):\n",
    "            if threshold - delta > 0:\n",
    "                threshold -= delta\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "sigma1 = 3\n",
    "sigma2 = 13\n",
    "threshold = 5\n",
    "delta = 0.05\n",
    "\n",
    "filename = ui_select_video()\n",
    "ejemplo(filename)\n",
    "\n",
    "print(\"FIN\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
